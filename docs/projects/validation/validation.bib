
@incollection{atamturkturEmpiricallyImprovingModel2017,
  title = {Empirically {{Improving Model Adequacy}} in {{Scientific Computing}}},
  booktitle = {Model {{Validation}} and {{Uncertainty Quantification}}, {{Volume}} 3},
  author = {Atamturktur, Sez and Stevens, Garrison N. and Brown, D. Andrew},
  editor = {Barthorpe, Robert and Platz, Roland and Lopez, Israel and Moaveni, Babak and Papadimitriou, Costas},
  date = {2017},
  pages = {363--369},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-54858-6_37},
  abstract = {In developing mechanistic models, we establish assumptions regarding aspects of the system behavior that are not fully understood. Such assumptions in turn may lead to a simplified representation or omission of some underlying phenomena. Although necessary for feasibility, such simplifications introduce systematic bias in the model predictions. Often times model bias is non-uniform across the operational domain of the system of interest. This operational domain is defined by the control parameters, i.e., those that can be controlled by experimentalists during observations of the system behavior. The conventional approach for addressing model bias involves empirically inferring a functional representation of the discrepancy with respect to control parameters and accordingly bias-correcting model predictions. This conventional process can be considered as experimental data fitting informed by theoretical knowledge, only providing a one-way interaction between simulation and observation. The model calibration approach presented herein recognizes that assumptions established during model development may require omission or simplification of interactions among model input parameters. When prediction accuracy relies on the inclusion of these interactions, it becomes necessary to infer the functional relationships between the input parameters from experiments. As such, this study demonstrates a two-way interaction in which theoretical knowledge is in turn informed by experimental data fitting. We propose to empirically learn previously unknown parameter interactions through the training of functions emulating these relationships. Such interactions can be posed in the form of reliance of model input parameter values on control parameter settings or on other input parameters. If the nature of the interactions is known, appropriate parametric functions may be implemented. Otherwise, nonparametric emulator functions can be leveraged. In our study, we use nonparametric Gaussian Process models in the Bayesian paradigm to infer the interactions among input parameters from the experimental data. The proposed approach will equip model developers with a tool capable of identifying the underlying and mechanistically-relevant physical processes absent from engineering models. This approach has the potential to not only significantly reduce the systematic bias between model predictions and experimental observations, but also further engineers’ knowledge of the physics principles governing complex systems.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Book Section\\Atamturktur et al-2017-Empirically Improving Model Adequacy in Scientific Computing.pdf},
  isbn = {978-3-319-54857-9 978-3-319-54858-6},
  keywords = {example},
  langid = {english},
  series = {Conference {{Proceedings}} of the {{Society}} for {{Experimental Mechanics Series}}}
}

@article{atamturkturUncertaintyQuantificationModel2012,
  ids = {atamturkturUncertaintyQuantificationModel2012a},
  title = {Uncertainty Quantification in Model Verification and Validation as Applied to Large Scale Historic Masonry Monuments},
  author = {Atamturktur, S. and Hemez, F.M. and Laman, J.A.},
  date = {2012-10},
  journaltitle = {Engineering Structures},
  volume = {43},
  pages = {221--234},
  issn = {01410296},
  doi = {10.1016/j.engstruct.2012.05.027},
  abstract = {This publication focuses on the Verification and Validation (V\&V) of numerical models for establishing confidence in model predictions, and demonstrates the complete process through a case study application completed on the Washington National Cathedral masonry vaults. The goal herein is to understand where modeling errors and uncertainty originate from, and obtain model predictions that are statistically consistent with their respective measurements. The approach presented in this manuscript is comprehensive, as it considers all major sources of errors and uncertainty that originate from numerical solutions of differential equations (numerical uncertainty), imprecise model input parameter values (parameter uncertainty), incomplete definitions of underlying physics due to assumptions and idealizations (bias error) and variability in measurements (experimental uncertainty). The experimental evidence necessary for reducing the uncertainty in model predictions is obtained through in situ vibration measurements conducted on the masonry vaults of Washington National Cathedral. By deploying the prescribed method, uncertainty in model predictions is reduced by approximately two thirds.},
  annotation = {ZSCC: 0000054},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Atamturktur et al-2012-Uncertainty quantification in model verification and validation as applied to.pdf;C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Atamturktur et al-2012-Uncertainty quantification in model verification and validation as applied to2.pdf},
  keywords = {example,model-validation},
  langid = {english}
}

@article{biUncertaintyQuantificationMetrics2017,
  title = {Uncertainty {{Quantification Metrics}} with {{Varying Statistical Information}} in {{Model Calibration}} and {{Validation}}},
  author = {Bi, Sifeng and Prabhu, Saurabh and Cogan, Scott and Atamturktur, Sez},
  date = {2017-10},
  journaltitle = {AIAA Journal},
  volume = {55},
  pages = {3570--3583},
  issn = {0001-1452, 1533-385X},
  doi = {10.2514/1.J055733},
  annotation = {ZSCC: 0000011},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Bi et al-2017-Uncertainty Quantification Metrics with Varying Statistical Information in.pdf},
  keywords = {example,parameter-interaction},
  langid = {english},
  number = {10}
}

@article{brownNonparametricFunctionalCalibration2018,
  title = {Nonparametric Functional Calibration of Computer Models},
  author = {Brown, Andrew and Atamturktur, Sez},
  date = {2018},
  journaltitle = {STAT SINICA},
  issn = {10170405},
  doi = {10.5705/ss.202015.0344},
  abstract = {Standard methods in computer model calibration treat the calibration parameters as constant throughout the domain of control inputs. In many applications, systematic variation may cause the best values for the calibration parameters to change across different settings. When not accounted for in the code, this variation can make the computer model inadequate. We propose a framework for modeling the calibration parameters as functions of the control inputs to account for a computer model's incomplete system representation in this regard, while simultaneously allowing for possible constraints imposed by prior expert opinion. We demonstrate how inappropriate modeling assumptions can mislead a researcher into thinking a calibrated model is in need of an empirical discrepancy term when it is only needed to allow for a functional dependence of the calibration parameters on the inputs. We apply our approach to plastic deformation of a visco-plastic selfconsistent material in which the critical resolved shear stress is known to vary with temperature.},
  annotation = {ZSCC: 0000015},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Brown-Atamturktur-2018-Nonparametric functional calibration of computer models.pdf},
  keywords = {example},
  langid = {english}
}

@incollection{chenUncertaintyModelingSimulation2017,
  title = {Uncertainty in {{Modeling}} and {{Simulation}}},
  booktitle = {Research {{Challenges}} in {{Modeling}} and {{Simulation}} for {{Engineering Complex Systems}}},
  author = {Chen, Wei and Kesidis, George and Morrison, Tina and Oden, J. Tinsley and Panchal, Jitesh H. and Paredis, Christiaan and Pennock, Michael and Atamturktur, Sez and Terejanu, Gabriel and Yukish, Michael},
  editor = {Fujimoto, Richard and Bock, Conrad and Chen, Wei and Page, Ernest and Panchal, Jitesh H.},
  date = {2017},
  pages = {75--86},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-58544-4_5},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Book Section\\Chen et al-2017-Uncertainty in Modeling and Simulation.pdf},
  isbn = {978-3-319-58543-7 978-3-319-58544-4},
  langid = {english},
  series = {Simulation {{Foundations}}, {{Methods}} and {{Applications}}}
}

@inproceedings{greenIdentificationModelError2018,
  title = {On the {{Identiﬁcation}} of {{Model Error}} through {{Observations}} of {{Time}}-Varying {{Parameters}}},
  author = {Green, P L and Chodora, E and Atamturktur, S},
  date = {2018-06},
  pages = {14},
  abstract = {When performing system identification, it can be possible to realise a deficient model (i.e. one that will make low fidelity predictions) that is able to closely represent a set of training data. For example, the parameters of linear dynamical models can often be tuned to realise a close match to training data that was generated from a system with strong nonlinearities. Despite this close match to available data, these same models may make very poor-quality predictions when shifted even slightly from the ‘validation domain’ (which could, for example, be a specific time window). In this paper we investigate the hypothesis that, by treating our model’s parameters as being time-varying, we can identify key weaknesses in a model that would have been difficult to establish using other identification methods that do not consider the potentially time-varying nature of the model’s parameters. Specifically, we use an Extended Kalman Filter to ‘track’ the parameters of a dynamical system, as a time history of training data is analysed. We then illustrate that this approach can reveal important information about the potential deficiencies of a model.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Green et al-On the Identiﬁcation of Model Error through Observations of Time-varying.pdf},
  keywords = {example},
  langid = {english}
}

@article{hemezDefiningPredictiveMaturity2010,
  title = {Defining Predictive Maturity for Validated Numerical Simulations},
  author = {Hemez, François and Atamturktur, H. Sezer and Unal, Cetin},
  date = {2010-04},
  journaltitle = {Computers \& Structures},
  volume = {88},
  pages = {497--505},
  issn = {00457949},
  doi = {10.1016/j.compstruc.2010.01.005},
  abstract = {The increasing reliance on computer simulations in decision-making motivates the need to formulate a commonly accepted definition for ‘‘predictive maturity.” The concept of predictive maturity involves quantitative metrics that could prove useful while allocating resources for physical testing and code development. Such metrics should be able to track progress (or lack thereof) as additional knowledge becomes available and is integrated into the simulations for example, through the addition of new experimental datasets during model calibration, and/or through the implementation of better physics models in the codes. This publication contributes to a discussion of attributes that a metric of predictive maturity should exhibit. It is contended that the assessment of predictive maturity must go beyond the goodness-of-fit of the model to the available test data. We firmly believe that predictive maturity must also consider the ‘‘knobs,” or ancillary variables, used to calibrate the model and the degree to which physical experiments cover the domain of applicability. The emphasis herein is placed on translating the proposed attributes into mathematical properties, such as the degree of regularity and asymptotic limits of the maturity function. Altogether these mathematical properties define a set of constraints that the predictive maturity function must satisfy. Based on these constraints, we propose a Predictive Maturity Index (PMI). Physical datasets are used to illustrate how the PMI quantifies the maturity of the non-linear, Preston–Tonks–Wallace model of plastic deformation applied to beryllium, a light-weight, high-strength metal. The question ‘‘does collecting additional data improve predictive power?” is answered by computing the PMI iteratively as additional experimental datasets become available. The results obtained reflect that coverage of the validation domain is as important to predictive maturity as goodness-of-fit. The example treated also indicates that the stabilization of predictive maturity can be observed, provided that enough physical experiments are available.},
  annotation = {ZSCC: 0000054},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Hemez et al-2010-Defining predictive maturity for validated numerical simulations.pdf},
  langid = {english},
  number = {7-8}
}

@article{khanIntegrationStructuralHealth2016,
  title = {Integration of {{Structural Health Monitoring}} and {{Intelligent Transportation Systems}} for {{Bridge Condition Assessment}}: {{Current Status}} and {{Future Direction}}},
  shorttitle = {Integration of {{Structural Health Monitoring}} and {{Intelligent Transportation Systems}} for {{Bridge Condition Assessment}}},
  author = {Khan, Sakib Mahmud and Atamturktur, Sez and Chowdhury, Mashrur and Rahman, Mizanur},
  date = {2016-08},
  journaltitle = {IEEE Trans. Intell. Transport. Syst.},
  volume = {17},
  pages = {2107--2122},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2016.2520499},
  abstract = {Recent catastrophic bridge failures clearly indicate the urgent need for improving interval-based bridge inspection procedures that are qualitative and subjective in nature. Structural Health Monitoring (SHM) can mitigate the deficiencies of interval-based inspection techniques and provide real-time diagnostic information regarding the bridge structural health. SHM is not flawless however; the variability in the vehicle characteristics and traffic operational conditions makes it prone to false diagnosis. Recent advancements in the integration of SHM with intelligent transportation systems (ITS) demonstrate the successful use of ITS devices (e.g., traffic cameras, traffic detectors) in the analysis of bridge responses to multimodal traffic with varying loads or during the critical events that cause excess vibration beyond the normal limit. In an ITS-informed SHM system, the ITS device collected data can be integrated with SHM to increase the reliability and accuracy of the SHM system. This integration would reduce the possibility of false diagnosis of damages detected by the SHM system (e.g., vibrations caused by heavy vehicles on a bridge could be read by a SHM sensor as a structural health problem of the bridge), which would eventually decrease the bridge maintenance costs. Similarly, in SHM-informed ITS system, SHM sensors can provide data on bridge health condition for ITS applications, where ITS uses this bridge health condition information for realtime traffic management. In this paper, literature related to both ITS-informed SHM and SHM-informed ITS is reviewed. Based on the literature review, potential challenges and future research directions associated with ITS-SHM integration are also discussed.},
  annotation = {ZSCC: 0000028},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Khan et al-2016-Integration of Structural Health Monitoring and Intelligent Transportation.pdf},
  langid = {english},
  number = {8}
}

@article{oberkampfVerificationValidationPredictive2002,
  title = {Verification, {{Validation}}, and {{Predictive Capability}} in {{Computational Engineering}} and {{Physics}}},
  author = {Oberkampf, William L and Trucano, Timothy G and Hirsch, Charles},
  date = {2002},
  pages = {74},
  url = {http://sokocalo.engr.ucdavis.edu/~jeremic/UsefulReadings/Oberkampf-Trucano-Hirsch.pdf},
  annotation = {ZSCC: 0000863},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Oberkampf et al-2002-Verification, Validation, and Predictive Capability in Computational.pdf},
  langid = {english}
}

@article{oberkampfVerificationValidationPredictive2004,
  title = {Verification, Validation, and Predictive Capability in Computational Engineering and Physics},
  author = {Oberkampf, William L and Trucano, Timothy G and Hirsch, Charles},
  date = {2004},
  volume = {57},
  pages = {40},
  annotation = {ZSCC: 0000863},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Oberkampf et al-2004-Veriﬁcation, validation, and predictive capability in computational engineering.pdf},
  langid = {english},
  number = {5}
}

@article{sevimAmbientVibrationTesting2016,
  ids = {sevimAmbientVibrationTesting2016a},
  title = {Ambient Vibration Testing and Seismic Behavior of Historical Arch Bridges under near and Far Fault Ground Motions},
  author = {Sevim, Barış and Atamturktur, Sez and Altunişik, Ahmet Can and Bayraktar, Alemdar},
  date = {2016-01},
  journaltitle = {Bull Earthquake Eng},
  volume = {14},
  pages = {241--259},
  issn = {1570-761X, 1573-1456},
  doi = {10.1007/s10518-015-9810-6},
  abstract = {This study investigates the effects of near and far fault ground motion on the seismic behavior of historical arch bridges through a combined numerical and experimental evaluation. The approach undertaken begins with finite element modeling of the arch bridge and identification of the most significant vibration modes of the bridge through ambient vibration testing. Uncertain parameters of the finite element model are then revised through systematic comparisons of the measured vibration models to those that are predicted by the model. The revised finite element model is used to predict the time history response for displacements and stresses through which the effect of the finite element model updating on model predictions are evaluated. Furthermore, displacements and stresses obtained considering both near and far fault ground motions are then compared. Results indicate that near fault ground motion imposes higher seismic demand on the arch bridge observed in both higher displacements and stresses.},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\00_Repo\\New-Files\\Sevim et al. - 2016 - Ambient vibration testing and seismic behavior of .pdf;C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Sevim et al-2016-Ambient vibration testing and seismic behavior of historical arch bridges under.pdf},
  keywords = {example},
  langid = {english},
  number = {1}
}

@article{stevensMitigatingErrorUncertainty2017,
  title = {Mitigating {{Error}} and {{Uncertainty}} in {{Partitioned Analysis}}: {{A Review}} of {{Verification}}, {{Calibration}} and {{Validation Methods}} for {{Coupled Simulations}}},
  shorttitle = {Mitigating {{Error}} and {{Uncertainty}} in {{Partitioned Analysis}}},
  author = {Stevens, Garrison and Atamturktur, Sez},
  date = {2017-07},
  journaltitle = {Arch Computat Methods Eng},
  volume = {24},
  pages = {557--571},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-016-9177-0},
  abstract = {Partitioned analysis involves coupling of constituent models that resolve different scales or physics by allowing them to exchange inputs and outputs in an iterative manner. Through partitioning, simulations of complex physical systems are becoming evermore present in the scientific modeling community, making the Verification and Validation (V\&V) of partitioned models to quantifying the predictive capability of their simulations increasingly important. Partitioning presents unique challenges, as well as opportunities, for the V\&V community. Verification gains a new level of complexity in partitioned models, as numerical errors can easily be introduced at the coupling interface where non-matching domains and models are integrated together. For validation, partitioned analysis allows the quantification of the uncertainties and errors in constituent models through comparison against separateeffect experiments conducted in independent constituent domains. Such experimental validation is important as uncertainties and errors in the predictions of constituents can be transferred across their interfaces, either compensating for each other or accumulating during iterative coupling operations. This paper reviews published literature on methods for assessing and improving the predictive capability of strongly coupled models of physical and engineering systems with an emphasis on advancements made in the last decade.},
  file = {C\:\\Users\\claud\\OneDrive\\Library\\Zotero\\Journal Article\\Stevens-Atamturktur-2017-Mitigating Error and Uncertainty in Partitioned Analysis.pdf},
  langid = {english},
  number = {3}
}


